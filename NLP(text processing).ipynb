{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TamCYE72faXk"
   },
   "source": [
    "Text Analysis\n",
    "1. Extract the Sample document and apply following document preprocessing methods: Tokenization, POS tagging, Stopwords removal, stemming and lemmatization.\n",
    "2. Create representation of document by calculating Term Frequency and Inverse Document Frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCnS0Qn5D1ja"
   },
   "source": [
    "# **Import the necessary libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jw1p0dnvBkmy"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLUlZDeLZt8w",
    "outputId": "8bfca289-58af-45f6-ba6a-c5f9f61ef11a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /home/kkw/anaconda3/lib/python3.9/site-packages (3.27.0)\n",
      "Requirement already satisfied: pandas in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: aiofiles in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: numpy in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (1.21.5)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (11.0.2)\n",
      "Requirement already satisfied: pydub in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.14.1)\n",
      "Requirement already satisfied: aiohttp in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: matplotlib in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: pyyaml in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: orjson in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (3.8.10)\n",
      "Requirement already satisfied: requests in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: pillow in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: typing-extensions in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: fastapi in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.95.1)\n",
      "Requirement already satisfied: semantic-version in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: uvicorn in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.21.1)\n",
      "Requirement already satisfied: gradio-client>=0.1.3 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.1.3)\n",
      "Requirement already satisfied: jinja2 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: ffmpy in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: httpx in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.24.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: pydantic in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (1.10.7)\n",
      "Requirement already satisfied: markupsafe in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: python-multipart in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: entrypoints in /home/kkw/anaconda3/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /home/kkw/anaconda3/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: packaging in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio-client>=0.1.3->gradio) (23.0)\n",
      "Requirement already satisfied: fsspec in /home/kkw/anaconda3/lib/python3.9/site-packages (from gradio-client>=0.1.3->gradio) (2022.11.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: filelock in /home/kkw/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from pandas->gradio) (2022.7)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kkw/anaconda3/lib/python3.9/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from fastapi->gradio) (0.26.1)\n",
      "Requirement already satisfied: idna in /home/kkw/anaconda3/lib/python3.9/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from httpx->gradio) (0.17.0)\n",
      "Requirement already satisfied: certifi in /home/kkw/anaconda3/lib/python3.9/site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: sniffio in /home/kkw/anaconda3/lib/python3.9/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kkw/anaconda3/lib/python3.9/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from matplotlib->gradio) (5.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kkw/anaconda3/lib/python3.9/site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: h11>=0.8 in /home/kkw/anaconda3/lib/python3.9/site-packages (from uvicorn->gradio) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from uvicorn->gradio) (8.0.4)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.11.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/kkw/anaconda3/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in /home/kkw/anaconda3/lib/python3.9/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/kkw/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "spIwGGEpZ9QD"
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5Rxk5fXBqe3",
    "outputId": "de712a95-a0fd-4c66-d427-cc63d69813e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kkw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2tVYpGNFYHL"
   },
   "source": [
    "# taken sent as our input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Tmn-WQcSB9Sk"
   },
   "outputs": [],
   "source": [
    "sent = \"Hello I am Gayatri Deshmukh. I am from Nanded District. I am a computer engineer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3gk1EYzFjJ6"
   },
   "source": [
    "## 1) Performing the Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcQyF_RBCKIj",
    "outputId": "4a06003a-9768-4b1c-c92c-8457744aad4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'I', 'am', 'Gayatri', 'Deshmukh', '.', 'I', 'am', 'from', 'Nanded', 'District', '.', 'I', 'am', 'a', 'computer', 'engineer', '.']\n",
      "['Hello I am Gayatri Deshmukh.', 'I am from Nanded District.', 'I am a computer engineer.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sent))\n",
    "print(sent_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tqeDnDEaDSFj"
   },
   "outputs": [],
   "source": [
    "#defining functions for tokenization\n",
    "def word_tokenization(input):\n",
    "  token = word_tokenize(input)\n",
    "  return token\n",
    "\n",
    "def sent_tokenization(input):\n",
    "  token = sent_tokenize(input)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "02oREVHIPKPg",
    "outputId": "0f857f21-6026-4eb8-f949-0b20d0d2e675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo1 = gr.Interface(fn=word_tokenization, inputs=\"text\", outputs=\"text\")\n",
    "demo1.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "q4ALAtadQiYG",
    "outputId": "425e8a2c-4211-42c8-d80f-0b251dce5b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo2 = gr.Interface(fn=sent_tokenization, inputs=\"text\", outputs=\"text\")\n",
    "demo2.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "mH_oHnP-H_Gz",
    "outputId": "2b18e852-936e-4929-a9bd-96088d5e156c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Blocks()\n",
    "with demo:\n",
    "    gr.Markdown(\"# Tokenization\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Word Tokenization\"):\n",
    "            with gr.Row():\n",
    "                word_ip = gr.Textbox(label=\"Input Data\")\n",
    "                word_op = gr.Textbox(label=\"Output Tokens\")\n",
    "            word_button = gr.Button(\"Generate Tokens\")\n",
    "        with gr.TabItem(\"Sentence Tokenization\"):\n",
    "            with gr.Row():\n",
    "                sent_ip = gr.Textbox(label=\"Input Data\")\n",
    "                sent_op = gr.Textbox(label=\"Output Tokens\")\n",
    "            sent_button = gr.Button(\"Generate Tokens\")\n",
    "        \n",
    "    word_button.click(word_tokenization, inputs=word_ip, outputs=word_op)\n",
    "    sent_button.click(sent_tokenization, inputs=sent_ip, outputs=sent_op)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDc95veIF-KK"
   },
   "source": [
    "## 2) StopWords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFOa2ViiC9iU",
    "outputId": "1d6ec11f-160f-4948-e00b-de248a275363"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kkw/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_4I1LTCnEUvS"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsnPKuA2EgKB",
    "outputId": "206b9280-460b-4179-85aa-95b036dbb316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unclean version  ['Hello', 'I', 'am', 'Gayatri', 'Deshmukh', '.', 'I', 'am', 'from', 'Nanded', 'District', '.', 'I', 'am', 'a', 'computer', 'engineer', '.']\n",
      "Clean Version ['Hello', 'I', 'Gayatri', 'Deshmukh', '.', 'I', 'Nanded', 'District', '.', 'I', 'computer', 'engineer', '.']\n"
     ]
    }
   ],
   "source": [
    "token = word_tokenize(sent)\n",
    "cleaned_token = []\n",
    "for word in token:\n",
    "  if word not in stop_words:\n",
    "    cleaned_token.append(word)\n",
    "\n",
    "print(\"Unclean version \", token)\n",
    "print(\"Clean Version\", cleaned_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YovCkwZ2GKFQ"
   },
   "outputs": [],
   "source": [
    "#defining a function for stopword removal\n",
    "def remove_stop(text):\n",
    "    return \",\".join([word for word in str(text).split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "OjhbL2rvTu-V",
    "outputId": "a60128f2-19e0-4eaf-882a-36ec84b92eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo3 = gr.Interface(fn=remove_stop, inputs=\"text\", outputs=\"text\")\n",
    "demo3.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OtSZrynGLEb"
   },
   "source": [
    "## 3) Stemmming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_UFln4zoOQf8"
   },
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xwpzboKHObPk"
   },
   "outputs": [],
   "source": [
    "text = \"Hello I am Gayatri. I am Engineering student.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nwxjYIs3OyN9"
   },
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(text)\n",
    "stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sV8Yh4cRPqPJ",
    "outputId": "36cecf79-8d52-4235-efe6-af847d926277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'i', 'am', 'gayatri', '.', 'i', 'am', 'engin', 'student', '.']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gkeFXeGoUq5F"
   },
   "outputs": [],
   "source": [
    "#defining a function for stemming\n",
    "def stemming(text):\n",
    "  word_tokens = nltk.word_tokenize(text)\n",
    "  stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n",
    "  return stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "PeVx63_8ZM1T",
    "outputId": "98e1bc69-9f2c-4cfa-8f01-8e9a26e79852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo4 = gr.Interface(fn=stemming, inputs=\"text\", outputs=\"text\")\n",
    "demo4.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njGCiqzxGYBf"
   },
   "source": [
    "## 4) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKbYLwAbq4zl",
    "outputId": "8a6d953f-605f-4e48-c63d-936298a09c43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kkw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAWTdugUrb8j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uPSr5udbp5H3"
   },
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(text)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer_word = [lemmatizer.lemmatize(word) for word in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVUafayQq7Kw",
    "outputId": "ae854de7-ef6b-45ea-a2c3-89ce0eda038f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n"
     ]
    }
   ],
   "source": [
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jl1FAzdqkaS",
    "outputId": "66f1b055-23f2-4f13-f258-47d47b74a172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'I', 'am', 'Gayatri', '.', 'I', 'am', 'Engineering', 'student', '.']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "K6covAvwYr-i"
   },
   "outputs": [],
   "source": [
    "# definig a function for lemmatization\n",
    "def lemmatization(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "vtcnzFWzZI68",
    "outputId": "08458efa-efe0-41a2-fc5e-a2fb351ac095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo5 = gr.Interface(fn=lemmatization, inputs=\"text\", outputs=\"text\")\n",
    "demo5.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceFN4vC8w74D"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ei5-kNvrFrZ",
    "outputId": "4e107a39-39c4-4912-f03e-31add9922eb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kkw/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ZIEWd6oLtNB-"
   },
   "outputs": [],
   "source": [
    "text = \"They are having their lunch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6TSKzqllt04i"
   },
   "outputs": [],
   "source": [
    "word_token = nltk.word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVFs0VK-ubHJ",
    "outputId": "0e57348d-b882-4d3c-9d7b-df6c472677ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They', 'PRP'), ('are', 'VBP'), ('having', 'VBG'), ('their', 'PRP$'), ('lunch', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_tag = nltk.pos_tag(word_token)\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg_Kj1SnxIRk"
   },
   "source": [
    "## TF IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1_ITg5Ud09Hu"
   },
   "outputs": [],
   "source": [
    "d0 = \"Good Morning\"\n",
    "d1 = \"Do daily exercise in the morning \"\n",
    "d2 = \"exercise is good for health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "X23UdqoY2Ab8"
   },
   "outputs": [],
   "source": [
    "series = [d0, d1, d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "eM2T32sv2EVP"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YB5Pzx7m2LTP"
   },
   "outputs": [],
   "source": [
    "result = tfidf.fit_transform(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIyhFUqB2RE1",
    "outputId": "68ca9554-fd63-48fd-93ff-766f130bfb18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Indexing \n",
      "{'good': 4, 'morning': 8, 'do': 1, 'daily': 0, 'exercise': 2, 'in': 6, 'the': 9, 'is': 7, 'for': 3, 'health': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Indexing \")\n",
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFRPwCZs2eKS",
    "outputId": "d68093ae-af71-4cbc-d2ab-7f0e9b74620d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf values :: \n",
      "  (0, 8)\t0.7071067811865476\n",
      "  (0, 4)\t0.7071067811865476\n",
      "  (1, 9)\t0.4403620672313486\n",
      "  (1, 6)\t0.4403620672313486\n",
      "  (1, 2)\t0.3349067026613031\n",
      "  (1, 0)\t0.4403620672313486\n",
      "  (1, 1)\t0.4403620672313486\n",
      "  (1, 8)\t0.3349067026613031\n",
      "  (2, 5)\t0.49047908420610337\n",
      "  (2, 3)\t0.49047908420610337\n",
      "  (2, 7)\t0.49047908420610337\n",
      "  (2, 2)\t0.3730219858594306\n",
      "  (2, 4)\t0.3730219858594306\n"
     ]
    }
   ],
   "source": [
    "print(\"tf-idf values :: \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "si15nHrr2l2J",
    "outputId": "20513f88-9f6a-42c1-fad6-d27e28300441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf in matrix form\n",
      "[[0.         0.         0.         0.         0.70710678 0.\n",
      "  0.         0.         0.70710678 0.        ]\n",
      " [0.44036207 0.44036207 0.3349067  0.         0.         0.\n",
      "  0.44036207 0.         0.3349067  0.44036207]\n",
      " [0.         0.         0.37302199 0.49047908 0.37302199 0.49047908\n",
      "  0.         0.49047908 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"tf-idf in matrix form\")\n",
    "print(result.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "T-qru1ls24_P",
    "outputId": "969b9717-4919-4da5-afd9-f2af64ebd183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = gr.Blocks()\n",
    "with final:\n",
    "    gr.Markdown(\"# NLP Operations\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Word Tokenization\"):\n",
    "            with gr.Row():\n",
    "                word_ip = gr.Textbox(label=\"Input Data\")\n",
    "                word_op = gr.Textbox(label=\"Output Tokens\")\n",
    "            word_button = gr.Button(\"Generate Tokens\")\n",
    "        with gr.TabItem(\"Sentence Tokenization\"):\n",
    "            with gr.Row():\n",
    "                sent_ip = gr.Textbox(label=\"Input Data\")\n",
    "                sent_op = gr.Textbox(label=\"Output Tokens\")\n",
    "            sent_button = gr.Button(\"Generate Tokens\")\n",
    "        \n",
    "        with gr.TabItem(\"Stopwords Removal\"):\n",
    "            with gr.Row():\n",
    "                sremo_ip = gr.Textbox(label=\"Input Data\")\n",
    "                sremo_op = gr.Textbox(label=\"Processed Data\")\n",
    "            sremo_button = gr.Button(\"Preocessed Data\")\n",
    "\n",
    "        with gr.TabItem(\"Stemming\"):\n",
    "            with gr.Row():\n",
    "                stem_ip = gr.Textbox(label=\"Input Data\")\n",
    "                stem_op = gr.Textbox(label=\"Output Stem\")\n",
    "            stem_button = gr.Button(\"Generate Stem\")\n",
    "            \n",
    "        with gr.TabItem(\"Lemmatization\"):\n",
    "            with gr.Row():\n",
    "                lemma_ip = gr.Textbox(label=\"Input Data\")\n",
    "                lemma_op = gr.Textbox(label=\"Output Lemma\")\n",
    "            lemma_button = gr.Button(\"Generate Lemma\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    word_button.click(word_tokenization, inputs=word_ip, outputs=word_op)\n",
    "    sent_button.click(sent_tokenization, inputs=sent_ip, outputs=sent_op)\n",
    "    sremo_button.click(remove_stop, inputs=sremo_ip, outputs=sremo_op)\n",
    "    stem_button.click(stemming, inputs=stem_ip, outputs=stem_op)\n",
    "    lemma_button.click(lemmatization, inputs=lemma_ip, outputs=lemma_op)\n",
    "\n",
    "final.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NF4V7r_xkkr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
